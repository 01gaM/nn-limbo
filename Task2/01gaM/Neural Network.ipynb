{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.302029, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301685, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301851, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.302623, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302031, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301124, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302831, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301638, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302170, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302117, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302455, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302807, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302832, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302390, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303278, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301772, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302333, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302433, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.301941, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302173, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19e273aac10>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de5Bk91XY8e/p1/Rjpntmumc1s1q9bAuUhcJGXmReMRBjl2RcVqAqiVRAqARQlELYIuUKIqaACn+kTJQUhCgoCiiQhFgEYxMVCMsUpCAJtksrW7alyLLW8mNXM7M7PY/umX7M9OPkj3t7tne2Z+ZOP++9Pp+qrenue2/3b3vuPfP7nft7iKpijDEmvCKTLoAxxpjRskBvjDEhZ4HeGGNCzgK9McaEnAV6Y4wJudikC9BLoVDQW2+9ddLFMMaYwHj++eeLqrrQa5svA/2tt97K+fPnJ10MY4wJDBH52mHbLHVjjDEhZ4HeGGNCzgK9McaEnAV6Y4wJOQv0xhgTchbojTEm5CzQG2NMyPmyH33f/urXoNXo/3gR+LZ/APk3Dq9MJ/HFP4XlFybz2caEwU13we3vnMxnX3kZXvzoYO+RyMD3Pjyc8nQJV6D/P78OjeoAb6BQ3YAfenRoRTqRp38WquuATObzjQk0hdlb4OHPT+bj/+9vwOc+zEDX7/QpC/TH+uDyYMf/+++AytpwynJSraYT5L/vEfiBX5hMGYwJso//C3j+dyf3+TtX4Ma3wk//5eTKcAjL0XdL590a9QTUNq6WwRhzcul5aFSgUZvM51eLvr1+LdB3S+ehUpzMZ3c+N+PPE8UY38sUnJ8Tu4bXIV2YzGcfwwJ9t0xhcjX6zuf69EQxxvc6184kr2GfVtQs0HdLu4G+3R7/Z1c7NXoL9Mb0pXPtVCdQo9+rQLPm24qaBfpu6TxoC+pb4//sTnPTpzk+Y3yvc+1UJlCj9/n1a4G+W2aCTb/91I0/TxRjfK9z7UyiRu/zFrkF+m77J8qEAn0yB9H4+D/bmDBIzoJEJ3T9dnrNWaD3v0neta8UfXuSGBMIkcjkes75vNecBfpuk276WdrGmMFMaixM1XL0wZGeZI1+3bf5PWMCI1OYXI0+Eoep7Pg/2wML9N3iSUhMX823jVN13be1AWMCY2I1ereiJv6cp8oC/UHp/PhTN6pXTxRjTP8yhQmlXv07KhYs0F9vEjdz6iVoN6xGb8yg0nmobTqTBI5TpejMteNTngK9iNwtIq+IyAUReaTH9h8Vkc+7//5GRN7s9VjfmUSNwKY/MGY4OtdQbczp12rR1y3yYwO9iESBx4B7gLPA/SJy9sBuXwG+T1W/DfhV4IkTHOsv6cL4c/SdQO/jE8WYQMhMaCxMCFI3dwEXVPU1Vd0DngLu7d5BVf9GVTfdp58Czng91ncyE0jd+Hz4tDGBMYmec62Gk371cUXNS6C/EbjY9fyS+9phfhL4s5MeKyIPiMh5ETm/tjahxT/ACbbNmjNJ0bj4vA+uMYExibEw+6nXYOfoe/UX0p47ivwATqD/+ZMeq6pPqOo5VT23sLDgoVgjMokaQcXf82QYExiTGN2+3yL37/XrJdBfAm7qen4GuG7NPhH5NuC3gXtVdf0kx/rKJCY2q65DLOUsDGyM6d9+jX6M99kCcI/NS6B/DrhdRG4TkQRwH/B09w4icjPwUeDHVfVLJznWdyaxeIH1oTdmOKJxZ3LAsaZu/F+jP3ZxcFVtishDwLNAFHhSVV8SkQfd7Y8DvwTkgf8gzsiwppuG6XnsiP4vw9HJs4276efj/J4xgTLusTAV/08xfmygB1DVZ4BnDrz2eNfjnwJ+yuuxvjaJVWqqNnOlMUOTHvNYmGoREF9X1mxk7EFTWWdyIkvdGBNMmTGPhamuQ2oOItHxfeYJWaA/SGQyTT+r0RszHGO/fv0/xbgF+l4yhfHV6Bs1aFR83ewzJlA6M1hqz57cwxeAFrmnHH1QfOjjX6TRbPd9vAj8vXM38U3jrBF0dc16+nPLfP7iBBYmNyYkzt06z92ZgjNJ4G7Z6YEzapUi5N/Ii6+X+OPPvj7QW2WmYvzcO79pSAW7KlSB/g/PX6S21+r7+Mpei53dJv8qU4DlF4ZYsqM+9GrXrA/+wReoN1okotbQMuakdptt/vQLK9x9T9egqXEE+uo63Pw2/uNfv8affH6ZdLz/XH1+esoC/XHO/+I7Bzr+Pb/5v1kp1eGGMc5J735ONT7Ldr3EI/fcwYPf98bxfLYxIfLos6/wW3/1ZVqpeaLgBOD8iK+ldnt/0aCVSzXedts8Tz3wXaP9zD5Y1bHLYjbFaqnu3Bitl5zJikbN7YO71poGYCmXHP1nGhNCi7kkrbayibuc3zjSr/Ut0BakC6yU6izlUqP/zD5YoO+ylEs6NfpxTnXqfsZyw5n+YDFrgd6YfnQqSZeb7lQiY7x+2+k8l8t1Fn1aUbNA32VpNkmp1mA34faAGcuJUgSJcrGaAOD0rD9rBMb4Xac2fWmvE+jHUKN3Y0RZcjTbymkL9P7XqREU1UmjjKXp5/bBXSnvAXAqOzX6zzQmhDrX76VKxJkkcFzXL3Cl5bbILXXjf4tZ55d0uekG+nHVCNJ5Vss1CtMJpmL+HV1njJ/NpuNMxSKslmpX+9KPmhsjlhv+vsdmgb7L6Vnnl/R6p+lXGVOOL+PvGznGBIGIcHo2dfU+2zgCvVujv1h3rl0L9AFwg3sj9GvVBCDjO1HSeVa2/Hsjx5igWMy6HSrShfGkbqobkJjm0o6SiEaYzyRG/5l9sEDfJRmPMp9JsLzdhNTsmFI3RbdGX/NtbcCYoFjKJZ0u0pkxzWBZdaYYXyk5FTV3mnbfsUB/wGI2ebUv/ahrBK0m1DbZS8xRrjetRm/MgBZzSS6X67RT8+NJvVacKcZXS/5ukVugP+D0bKcv/RgmNqttAlCKOMO0T1uO3piBLM2maLaVamzWmSywURvtB3Za5OWab7tWggX66yzmkqyM666927Rcb8/sf7Yxpn9L7n22Ddw5bkZ+DW+g6bxbo/dvRc0C/QFLuRRb1QbN5PzoUzfu+6/a9AfGDEWnslRsj2ksTKVILTZLo6W+vn4t0B/QmYJgJzrr1Aba/U97fKxOH9y9NHC1148xpj+dYLvSGMPo2L0KNGv7qVc/t8gt0B+w5Pal3yTrTFZUH+H88G6z8qu1FPlMguQA05saY2A+kyARi3Bx16k8jXRJQbe1sK5O6tXP99gs0B/QGbS05ubNR3uiOIH+tcqUr2sDxgSFiLCUS/KVmht0R5m6cStqnZH0fr6GPQV6EblbRF4RkQsi8kiP7XeIyCdFZFdEPnBg2/tF5EUReUlEHh5WwUelk7pZbXZqBKM8UZyFES6Vm77O7xkTJIvZJF/ZjoJER3z9OoH+9b0M8aiQ9+lgKfAQ6EUkCjwG3AOcBe4XkbMHdtsA3gc8euDYbwV+GrgLeDPwHhG5fQjlHplUIspsOn616TfKGoE7KnbVx9ObGhM0p2dTLJf3nHWYR339Al+vJ7khmyQS8edgKfBWo78LuKCqr6nqHvAUcG/3Dqp6RVWfAw6u1PG3gE+palVVm8BfAT88hHKP1FIuxVeqbtNvxDWCVirPVrVh89wYMySdQVOaHvFYGDc2vFpJ+To/D94C/Y3Axa7nl9zXvHgReLuI5EUkDbwbuKnXjiLygIicF5Hza2trHt9+NJZySS7suNMFj/REWacen9v/TGPM4JZySRotpZGcG/n1SyTOV8oR37fIvQT6Xu0R9fLmqvoy8CHgz4GPA58Dmofs+4SqnlPVcwsLC17efmQWc0m+vq0Qz4x2GHWl6HTjxN83cowJks59tmpsbuSpG03nWS3v+r6i5iXQX+LaWvgZYNnrB6jq76jqnar6dpxc/qsnK+L4LWWTbFT2aKdHuEi4KlTX2RKnd4+lbowZjs4qbeVIdgyp13n2Wm3fV9S8BPrngNtF5DYRSQD3AU97/QAROeX+vBn4EeDD/RR0nJbcE6UxNcKbObtlaDf2u3H6vUZgTFB0gu6GzkBty5k8cBQqxa7Uq78rarHjdlDVpog8BDwLRIEnVfUlEXnQ3f64iCwC54Es0Ha7UZ5V1TLwRyKSx7lR+zOqujmq/8ywdIJuNT7L1KhyfO4fkJVGhrl03AZLGTMk8+kEiWiEK60ZQJ3JA6dHkA6urrOTuQPwf0Xt2EAPoKrPAM8ceO3xrserOCmdXsf+7UEKOAmdGsF2JMvczpdH8yHuH5BLuxlfT4ZkTNBEIsINuSmWu6dBGEmgL7I1HYwWuY2M7WFpv+mXHV3qxn3fr9aSvp7e1JggWsql+Hp9hKNjWw2olyi2Z4hFhML01PA/Y4gs0PeQTsTIpeJO069ZcyYvGja3Rv/qjk1/YMywLeWSvFZ1r6tRpF/d91xpTvt+sBRYoD/UUi7J6/tNv1GcKE4t4yu1lO+bfcYEzWIuyavbnUA/ghr9fuo1HYjr1wL9IRZzSS7ujrDpVynSjiWpkbQcvTFDdjqX4nLLraiNYiyMGxO+VksGokVugf4QzjQIo236NRJO1yzL0RszXIu5JE1itBIj6kvfmf5gJ7nfb9/PLNAfwsnxjbBGX12n6vbBDUKNwJgg6aRT6okRTYPgthJWm9P7I3H9zAL9IRZzSTa1Myf9aJp+5QCsTGNMEHWuqUpsdmQVNYAtpi1HH2RLuSRl0rQj8ZE1/TbJkkvFSSc8DWcwxnhUyEwRjwolyY6sM0UjMUuLaCAqahboD+EMaRZ246OqEWyw1soEojZgTNBEIsIN2STr7ZmRdaaoxp0JCS1HH2DXNP2GXSNo1GFvh+VGMJp9xgTRUi7JanPauX7V04S73lXX2Y7kiAZgsBRYoD/U9FSMmWSM8iiafm4q6GI9ZV0rjRmRxVyK1xtpaDecSQSHqbrOJjPcMDNF1OeDpcAC/ZGWcklnhfdhN/06S5AFZLCFMUF0Opfka7URLQlaKbLWmglEfh4s0B9pKZditTU9/JuxbgthQ2cs0BszIou5JFc6g6aqG8N743YbqussNzL7U5r7nQX6Iyzlkry+l4F6yZnEaFg6gZ6s7+exNiaolnJJZ2JCGG5lrb4F2nJa5AHoQw8W6I+0mEtyaddt+g2zRuA2I9c1G5imnzFBs5RLsYEb6IeZunFjwZXmdGCuXwv0RzidSzmr1MBwawTVIm2ilLEcvTGjsn+PDYZ+/QJsMBOIrpVggf5Ii7nkiGoE61RjWWaSCTJTNljKmFHIT0/RiCRpyNRwe84FsEVugf4ITo1gBDm+SpGS5Cw/b8wIRSPCDdkUO9HccGew7NToNRuYFrkF+iNcO9/NEHP01XXWNThds4wJqqVckk0Z8gyWnXluZIaFAAyWAgv0R5pJxmlOOcOch5q6qRS53Jrm9KwFemNGaTGXpDjsaRAq6+xGUsxms8SiwQihwSjlBC3kMuxEZoZaI9DqOquNDItZS90YM0pLuSSrjQw6zBx9tUhJgpOfB4+BXkTuFpFXROSCiDzSY/sdIvJJEdkVkQ8c2PZzIvKSiLwoIh8WkeB8Ozg1gi3JDa9G0G5BbdPtQx+or8KYwFnMpVgbeo2+GKj8PHgI9CISBR4D7gHOAveLyNkDu20A7wMePXDsje7r51T1W4EocN8Qyj02S7kkxfb08O7aVzcQ1HL0xozBabeLpTQqzmSCQ6DVda60gtUi91Kjvwu4oKqvqeoe8BRwb/cOqnpFVZ8Deg0fjQEpEYkBaWB5wDKP1VIuxeXmNDqsGoGbAtrUGcvRGzNii7kkmwy3L71Wiqy1g3X9egn0NwIXu55fcl87lqq+jlPL/zqwApRU9RO99hWRB0TkvIicX1tb8/L2Y9EZdNEeWqB3WgbrZG3mSmNGbCmX6poGYVit8mKg+tCDt0Dfaw5OT5M7i8gcTu3/NuA0kBGRH+u1r6o+oarnVPXcwsKCl7cfi86gqUhtw5nMaFDuH4zd+BzTNljKmJFamJlyulfCcPL0exUizXrgJiT0EugvATd1PT+D9/TLDwJfUdU1VW0AHwW++2RFnKylXIpNnUG0Bbulwd/QbT7GZvzzx8yYsIpGhEi64DwZRo1+f0LCmUC1yL0E+ueA20XkNhFJ4NxMfdrj+38d+E4RSYuIAO8AXu6vqJOxNNs1OnYYo+vc90jPnRr8vYwxx0rk3ErVMGr07ntskuXUTDAGS4Fzo/RIqtoUkYeAZ3F6zTypqi+JyIPu9sdFZBE4D2SBtog8DJxV1U+LyEeAzwBN4LPAEyP6v4zEzFSMaiznPKkWgTcN9obVdbZJcyo3M3DZjDHHy84u0CpGiA6xRt9O5YkHZLAUeAj0AKr6DPDMgdce73q8ipPS6XXsLwO/PEAZJ0pEiEwvQJWh1AhaO2sU29a10phxWZxNs6kz5CvFnjccT8SNAbFssFrkwfmTNEFTnV/qEGoEje01GyxlzBgtuj3nmttD6M3nxoC0BfrwSc/d4DwYQj/c9s6ac8c+IPNYGxN0S7kUm8zQ2L4y8HtppUhDo8zO54dQsvGxQO/BwlyOik7R2hk80EttI3DDp40Jsk6Nfhjz3TS2r7BB8CpqFug9WHQHXeyWBqwRqJLY3XC7ZlmgN2YcTs86a8dGa4NPNb5XXmNDgzfY0QK9B0uzSTaYoTFojm+3TFSb7ERnySbjwymcMeZIC9NTbJJlqlFyJhUcQGunyIbOcDpgFTUL9B44q8nPDD7fjXt8OzU/hFIZY7yIRSM0puYQdOAFhKS6HsgWuQV6D5ayzmry0fqAOT73JItO26hYY8ZJhzQ61km9Zjk1Y4E+dLKpGCXJkdzbHOyN3F478awFemPGaf+aG6TnXKtBsrVNPT5HIhas0Bms0k6IiNBKzhFv78Jete/3ae44Of7M3OKwimaM8WAq63SRHij96rbINYCpVwv0Hmmm0/Tr/0SpbKwCkMtboDdmnGbmnQFO9dLl/t/EvfYlgKlXC/QexaYHnxipVrpCXeMU5ueGVCpjjBezC07lqrI5QBdp99qfCtioWLBA71ky5/xyWzv9d7FslNdYJxu4wRbGBN3iXJaypgeq0dfcY1OzFuhDa3reyfFtb/RfI9BK0V2wwAK9MeO0mEuxrjO0tvtvke9sOIE+iKlXC/QezRaWANjZXO37PaK1dUqSJZu0laWMGadTM1PO2rED3GOrbjqBfn5haVjFGhsL9B4V8qdoaJTdAZp+U3tb1OJzOGuwGGPGJR6NsBOdJb7bfxfpxvYamzrN0tz0EEs2HhboPVqadWbAaw7Q9Mu0tmgmg9c1y5gw2J2aJ9noP9C33dTrqWxwVpbqsEDv0Ww6zibZ/kfWNeqktHZ1hJ4xZqxayXlmWiVQ7ev4aG2D7UiOqVh0yCUbPQv0HokIldgssT6nQegMlopNW6A3ZhIimQJxmrC73dfxib0NavFgdo22QH8C9fgcqcZWX8duFlcAmMoFr2uWMWHQmQah3w4VmeYWjYCmXi3Qn0A7Nc90q79Av+UG+pn54HXNMiYMUrNOF+nNK8snP7jdJqtlSFugDz3JFMhSodXYO/GxO+tuH9xC8LpmGRMGWbf/e2n95DX6SnmDGO3AzjzrKdCLyN0i8oqIXBCRR3psv0NEPikiuyLyga7Xv1lEXuj6VxaRh4f5HxinmNv02yie/ESpu6tTFU5ZoDdmEubcSlZ16+RdpItXXgeCm3o9NtCLSBR4DLgHOAvcLyJnD+y2AbwPeLT7RVV9RVXfoqpvAd4KVIGPDaPgk5DKOU2/9T6afq2dNZoaITsXzBqBMUGXP3UagN3yyacx2VpzUq9BnXnWS43+LuCCqr6mqnvAU8C93Tuo6hVVfQ5oHPE+7wC+rKpf67u0EzaTdwJ9eX3l5AdXi5QjM0gkeF2zjAmDRGqGOgnafcxX1bmBO1sIb6C/EbjY9fyS+9pJ3Qd8+LCNIvKAiJwXkfNrawOuzToi8wWnRlDZPHnTL1bfoBKdHXaRjDFeibAdyRGpnbyLdL3kxKS5hdPDLtVYeAn0vcbrn2jEgYgkgPcCf3jYPqr6hKqeU9VzCwv+TG90bubs9dH0S+5tsZsIZh9cY8KiFsv1NQ1CY9u55pNhzdHj1OBv6np+Bjhpkvoe4DOqOsCs/5Mn6Txw8qmKW21lur1FK6B9cI0Ji72pedLNk3eRlkqRGkmIB3PmWS+B/jngdhG5za2Z3wc8fcLPuZ8j0jaBEY2xI9NEaidbSb64s8s8ZcjYqFhjJqmdzjPbLrGz2zzRcdH6BpVYbkSlGr1jA72qNoGHgGeBl4H/oaoviciDIvIggIgsisgl4J8Bvygil0Qk625LA+8EPjqq/8Q4VeNzxOsnC/TLGzvMUrFFwY2ZsOj0AvOyzWqpdqLjko1N6gGd/gDA08ToqvoM8MyB1x7veryKk9LpdWwVyA9QRl/Zm5ojXd+k3VYiEW/TDW8ULxMRJRXQ/J4xYZHILjAtdVY3Srzp1IynY6p7TbLtEq1UMG/Ego2MPbF2Ks8c2xQru56PKe1Pf2CDpYyZpMycOw3Cmvcu0qulOvOyDeng1lct0J9QJFNwm351z8d0RuJ1TjJjzGR05pra2fA+un21VGeebeIzwU29WqA/oancKebYZnnTe46vM/2B2M1YYyYqPuOkT2snmAbh8vomadkN5KLgHRboTyg1ewNxabGx7n2R8PaOuypVgJt+xoSCew3unWCluM5I+OkAzzxrgf6E0u5Up9snaPpJZySeBXpjJsttVWvFe6DvjITvtAaCyAL9CUXcE6W65a1G324rid0N6tFpiCVGWTRjzHGSs7SIEj3BNAi7buo1yBU1C/QnlXF+2Q2P0yAUd3aZo8zelI2KNWbiIhF24zmmm1tU97wNmmp2Uq8Bvsdmgf6k3MW9teot0K+U6syxTTtlgd4YP2gm55iTbVY89pyL1IJ/j80C/Um5v+xYbYN2+/i53VZKdfKyvZ/yMcZMWNp7F+l6o0WqsUVLopAM8RQI5oBEmkYkSVbLrFeOX1JwpVRjXsokssG9kWNMmERnFshTZnnr+C7SnRb5XmIOxNtIeD+yQN+HZjLPvJQ91QhWt2rMUw7sEmTGhM1U9pTn63elVCMvZdqp4KZtwAJ9XzSdJ882Kx4mRtrc3CAhrf0pjo0xkxWbLjArFVZLlWP37Ux/EPTUqwX6PkRnFpwaQfn4GsH+CLyAnyjGhEamQARlZ/P4DhUrpTrzlIkHPPVqgb4PiRnnZs7y1vGBfm+70wfXAr0xvuC2rr1Mg7BSqpGPbBObDvb1a4G+D5JZIO9hTut2W6EzAi9jqRtjfMFtXXtZKW5ta4cclcC3yC3Q9yOdJ8Uu61tHL0m2Xtkjq+X9Y4wxPuBei/HdLWp7rSN3rWytXXNMUFmg74f7S98fGn2IzvSmzjHBrhEYExrutZj3cJ+tUQ7+9Adggb4/bjOusV1E9fBBU8tuH/p2dAoSmXGVzhhzFDdoz1Nm5Yi+9PVGi0hn2VBL3XwDcmsE2XaJjSMGTa26o2I1XQj0YAtjQiWWoJ3IMn/MNAiXy+FpkVug74f7132e8pEnytXpD4Ld7DMmdDJ5ZxqEI1I3K6U68+LeY7Ma/TegtDNB2XGj61ZLNW6I7djKUsb4TCRT4Ibo0YMenRa5G+hTc2Mq2Wh4CvQicreIvCIiF0TkkR7b7xCRT4rIroh84MC2WRH5iIh8UUReFpHvGlbhJyY5i0ZibtPv8BNl2a3RB73ZZ0zopAssRHdYOWIszHKpxhzbaHIWovExFm74jg30IhIFHgPuAc4C94vI2QO7bQDvAx7t8Ra/AXxcVe8A3gy8PFCJ/UAE0nkKx+T4Vkt1cloOfLPPmNDJ5Jnj+Os3LC1yLzX6u4ALqvqaqu4BTwH3du+gqldU9Tmg0f26iGSBtwO/4+63p6pHdz4PCEkXWIpXDk3dqCrrpW2S7ep+qscY4xPpPNl26chBjyulOovRSiha5F4C/Y3Axa7nl9zXvHgDsAb8ZxH5rIj8toj07GcoIg+IyHkROb+25m1Rj4lKz3MqunNojWCjssdMy/2bFoITxZhQSReIaYO9aol6o/egqdVSnXykHPg+9OAt0PfqF3j8ihuOGHAn8Fuq+u1ABbguxw+gqk+o6jlVPbewsODx7ScoU3Cbfr1rBJ0eN519jTE+0uk5d8QCJCulmpt6/cYI9JeAm7qenwGWPb7/JeCSqn7aff4RnMAffOkC2fYWK6V6z0FTK6U6cxKOPrjGhE6600W6d55+t9miuLNLplUKxfXrJdA/B9wuIreJSAK4D3jay5ur6ipwUUS+2X3pHcD/66ukfpMpkGpt02rusVVtXLd5teQsOAKEoulnTKh0RsdKmdXy9a3yK+VdslSIaisULfLYcTuoalNEHgKeBaLAk6r6kog86G5/XEQWgfNAFmiLyMPAWVUtAz8L/L77R+I14B+N6P8yXu6JMseO0w0rk7hm83KpzkLEUjfG+JKbjslLued048tbtaup1xBU1I4N9ACq+gzwzIHXHu96vIqT0ul17AvAuQHK6E+dQO/m+L7l9LULB6+W6rx5qgrtKCRnJ1FCY8xh3HTMjYlqzxz9atlZK7Z73yCzkbH9ylydAa9Xjm+lVON0wu1aGbGv2RhfSWQgluTGRPWQ67drVGwIbsZ6qtGbHty/8oVI77v2q6U6p6I7EPBFhY0JJXfQ42Jrp2eOfrVU53TCXVPWavTfwNzUzS3JGssHuliq6tUJkUJwkhgTSuk8C5He0yAsb9W4Zaq6v1/QWaDvlzva9czU9Tm+zWqD3WabbKsUimafMaGUKTBLifXK3nWDplbLdZYSVYinIZGeUAGHxwJ9v6JxSM6yFLt+GoTOIKp0c8tq9Mb4VbrAdKsEON0pu610Uq8huX4t0A8iU6AQ2b5u0NRqqU6ENvG9rVA0+4wJpXSe5J4zTUn3CPe9Zpvizq5zMzYkLXIL9INI55mjTK3RolS7OmhquVRnlh0EtT70xvhVJk+suUOCxjU9by6X66g6K8iFpaJmgX4QXU2/7hNltVS7OlgqJCeKMaGT7r1SXGfVqXQzHNMfgAX6wWTypBqbANfk6VdKdd6YcZ9bjd4Yf3KvzZuStWumK+4E/cTuRmiuXwv0gwnVDcEAAAz9SURBVEgXiO1uAnqgRl/ntrT73Gr0xviTe22+KVO/rkWeZJdIsxaa69cC/SDSeaTdZFYq19zMWSnVObPfBzccNQJjQse9Nm9J1a4J9MtbdW4KUR96sEA/GLdZd/v03v6J4gyWqrEU23H2CcmJYkzoZDrz3VSua5G/aXr3mn2CzgL9INwawRun6/s5+lKtQb3RZiG6A1M5iCWOegdjzKQkZ0EinIpWKO7sstdsA7BSrnNbym2hh6RFboF+EG4f21uTtf3UTadmMEfZ1oo1xs8iEUjNU3AnL7vs9rZZLdW4uZO6sRq96aRlOjPgddI2gNPtMiQniTGhlSk4ywXiVNIarTZXtndZjHcmNAtHZc0C/SDcZt0N0R2qey3K9eZ+jT7V2AxNs8+Y0EoXyDSvjo69sr2LKk7qNRILzVoSFugHkUhDPE3eHRy1WnJy9dGIEKtvhmb4tDGhlckztXd1LEynP72Tes070xmHgAX6QaULzKozOna5VGN5q86p6QRSLVqPG2P8Lp0nUltnJhljpVTfX1ZwJiSLgndYoB9Uen6/6bdaqrNarnFbVqG1F6oTxZhQShegusGN2Tgrpdp+7zkn9RqO/DxYoB9cpkBibwsR52bOSqnOmzK1/W3GGB/LFADljTNNVt3rN52IEq2HZ/oDsEA/uHSBSHWdUzNTrGw5NYJbUrv724wxPuamV9+QdoL8arnGUi6JVIqhun49BXoRuVtEXhGRCyLySI/td4jIJ0VkV0Q+cGDbV0XkCyLygoicH1bBfSOdh2qRxVyKL13eprrX4sxU5eo2Y4x/udfozckqazu7fH2jyplsHOrhWkvi2EAvIlHgMeAe4Cxwv4icPbDbBvA+4NFD3uYHVPUtqnpukML6UiYPjSo3T8NLy05/3BuiO1e3GWP8y03PnI5XUIUvrmzzhky4pj8AbzX6u4ALqvqaqu4BTwH3du+gqldU9Tmg0esNQs1t3r0hU6fZdlaZKkTK12wzxviUe40uuJWzZlu5JRW+mWe9BPobgYtdzy+5r3mlwCdE5HkReeCwnUTkARE5LyLn19bWTvD2E+b+1b8lWd1/aVa3IZaERGZSpTLGeOEG83nZ3n/pTMimPwBvgb7XiAHt8dphvkdV78RJ/fyMiLy9106q+oSqnlPVcwsLCyd4+wlzT5SlhHNyRKSzKHh4BlsYE1qxBExlyborxQEshnDmWS+B/hJwU9fzM8Cy1w9Q1WX35xXgYzipoPDYnwbBqREszEwRqa6H6iQxJtTSeRK7G0xPxQD2JzkLU+rVS6B/DrhdRG4TkQRwH/C0lzcXkYyIzHQeA+8CXuy3sL7k3nCdwwn0i7kUVNdD1ewzJtQyBaius5hLApCjs95zeAZMxY7bQVWbIvIQ8CwQBZ5U1ZdE5EF3++MisgicB7JAW0QexumhUwA+Jk4KIwb8d1X9+Gj+KxOSnAWJkm2VEIHTuSSsF2H+DZMumTHGi3QBypdYyiV5fbNGcm/Tua6j8UmXbGiODfQAqvoM8MyB1x7veryKk9I5qAy8eZAC+p4IpPNE6+u89eY53nrLHHzdUjfGBEY6Dyuf49yb5xGRUM5T5SnQm2NkClBZ5yP/9LuhuQt/sW196I0Jiowz6PH973iTU3H73X8ZutSrTYEwDOm8k5eHqz9DdCPHmFBLF5xJCPfc3jbVjdBdvxbohyFTgGrReVwpXn3NGON/nWu1c+1Wi6FrkVugH4Z0/tqTpPOaMcb/OtdqdR1UnZ8hu34t0A9DuuBMgtRqQMVSN8YESrqrRl/fgnYzdNevBfph6DT9aptXc/SWujEmGDJdNfrqhvtauK5fC/TD0GnmVYpO6kYioVlU2JjQ69Teq8WrKVir0Zvr7Of43BMlNQ8R+2qNCYREBqJTVytqEKpRsWCBfji679pXi6Fr9hkTaiL70yCEtdecBfph2G/6rYeyD64xodcZCxPScTAW6Ieh08zr1AhC1gfXmNDLFNwW+TrE05BIT7pEQ2WBfhiicUjmrqZuQtYH15jQc9d+phLO69cC/bCkC1C5YqkbY4Io7cxXFdaKmgX6YckUYP3LgIbuRo4xoZfJw942lFdCef1aoB+WdAGKr7qPw1cjMCbUOq3w9QuhbJFboB+W9Dy0dt3HFuiNCZTONdvaDeX1a4F+WLqbeyFs+hkTatdcvxbozWG6m3shbPoZE2ohv34t0A9Ld40gZMOnjQm97nRNCFvkFuiHpXOiTGUhNjXZshhjTiY150xGCJajN0fonBwhPEmMCb1IxJmMEL5xUzcicreIvCIiF0TkkR7b7xCRT4rIroh8oMf2qIh8VkT+ZBiF9qVOcy+EzT5jviHsX8Phq6wdG+hFJAo8BtwDnAXuF5GzB3bbAN4HPHrI27wfeHmAcvpfpxZgNXpjgimdB4mGci0JLzX6u4ALqvqaqu4BTwH3du+gqldU9TmgcfBgETkD/BDw20Mor38l0hBLhbLZZ8w3hHTeDfYy6ZIMXczDPjcCF7ueXwLedoLP+HXgnwMzR+0kIg8ADwDcfPPNJ3h7H3nXr8LSWyZdCmNMP972T+D2d026FCPhpUbf68+benlzEXkPcEVVnz9uX1V9QlXPqeq5hYUFL2/vP3f9NNz0HZMuhTGmH7d+L9z545MuxUh4CfSXgJu6np8Blj2+//cA7xWRr+KkfP6OiPy3E5XQGGPMQLwE+ueA20XkNhFJAPcBT3t5c1X9BVU9o6q3usf9par+WN+lNcYYc2LH5uhVtSkiDwHPAlHgSVV9SUQedLc/LiKLwHkgC7RF5GHgrKqWR1h2Y4wxHoiqp3T7WJ07d07Pnz8/6WIYY0xgiMjzqnqu1zYbGWuMMSFngd4YY0LOAr0xxoScBXpjjAk5X96MFZE14Gt9Hl4AikMszrBZ+QZj5RuMlW8wfi7fLarac7SpLwP9IETk/GF3nv3AyjcYK99grHyD8Xv5DmOpG2OMCTkL9MYYE3JhDPRPTLoAx7DyDcbKNxgr32D8Xr6eQpejN8YYc60w1uiNMcZ0sUBvjDEhF8hA72GxchGRf+du/7yI3Dnm8t0kIv9LRF4WkZdE5P099vl+ESmJyAvuv18acxm/KiJfcD/7uhnkJvkdisg3d30vL4hI2Z0RtXufsX5/IvKkiFwRkRe7XpsXkT8XkVfdn3OHHHvk+TrC8v1rEfmi+/v7mIj0XAz1uHNhhOX7FRF5vet3+O5Djp3U9/cHXWX7qoi8cMixI//+BqaqgfqHM1Xyl4E3AAngczhTInfv827gz3BWx/pO4NNjLuMScKf7eAb4Uo8yfj/wJxP8Hr8KFI7YPtHv8MDvexVnMMjEvj/g7cCdwItdr/0a8Ij7+BHgQ4eU/8jzdYTlexcQcx9/qFf5vJwLIyzfrwAf8PD7n8j3d2D7vwF+aVLf36D/glijP3axcvf5f1HHp4BZEVkaVwFVdUVVP+M+3gZexll7N0gm+h12eQfwZVXtd6T0UKjqXwMbB16+F/g99/HvAX+3x6FezteRlE9VP6GqTffpp3BWh5uIQ74/Lyb2/XWIiAB/H/jwsD93XIIY6HstVn4wiHrZZyxE5Fbg24FP99j8XSLyORH5MxH5lrEWzFn39xMi8ry7MPtBfvkO7+PwC2yS3x/ADaq6As4fd+BUj3388j3+Y5wWWi/HnQuj9JCbWnrykNSXH76/vw1cVtVXD9k+ye/PkyAGei+Llfe9oPkwicg08EfAw3r9alufwUlHvBn4TeCPx1y871HVO4F7gJ8Rkbcf2D7x71CcpSvfC/xhj82T/v688sP3+EGgCfz+Ibscdy6Mym8BbwTeAqzgpEcOmvj3B9zP0bX5SX1/ngUx0HtZrHyQBc2HQkTiOEH+91X1owe3q2pZVXfcx88AcREpjKt8qrrs/rwCfAynidxt4t8hzoXzGVW9fHDDpL8/1+VOOsv9eaXHPhP9HkXkJ4D3AD+qbkL5IA/nwkio6mVVbalqG/hPh3zupL+/GPAjwB8cts+kvr+TCGKg97JY+dPAP3R7jnwnUOo0scfBzen9DvCyqv7bQ/ZZdPdDRO7C+V2sj6l8GRGZ6TzGuWn34oHdJvodug6tSU3y++vyNPAT7uOfAP5nj328nK8jISJ3Az8PvFdVq4fs4+VcGFX5uu/5/PAhnzux78/1g8AXVfVSr42T/P5OZNJ3g/v5h9Mj5Es4d+M/6L72IPCg+1iAx9ztXwDOjbl834vTvPw88IL7790HyvgQ8BJOL4JPAd89xvK9wf3cz7ll8ON3mMYJ3Lmu1yb2/eH8wVkBGji1zJ8E8sBfAK+6P+fdfU8Dzxx1vo6pfBdw8tudc/Dxg+U77FwYU/n+q3tufR4neC/56ftzX//dzjnXte/Yv79B/9kUCMYYE3JBTN0YY4w5AQv0xhgTchbojTEm5CzQG2NMyFmgN8aYkLNAb4wxIWeB3hhjQu7/A3b3OZludZF/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.275985, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.347515, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264348, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287890, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253264, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265011, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.212698, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.320777, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302624, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.311032, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.234316, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283390, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.353994, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.217454, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.378711, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256101, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.309860, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264767, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276485, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274562, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.322051, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308033, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.317549, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262630, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270323, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308261, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264990, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278636, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267083, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279901, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276510, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.314133, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256404, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295822, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290051, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278750, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280567, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.255044, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240982, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.315651, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.351801, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.319693, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.295926, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.345443, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.310013, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.326544, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.255641, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.199259, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.164561, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.025661, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.883798, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.263931, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.662918, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.245522, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.943906, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.663953, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.042200, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.418303, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.519709, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.823944, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.022291, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.585656, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.937038, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.908215, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.233499, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.095108, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.718242, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.162756, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.015933, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.363952, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.842670, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.657567, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.388463, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.911120, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.693765, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 2.010436, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.115900, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.613706, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.738574, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.885192, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 2.474042, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.119274, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.672047, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.767860, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.478802, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.926619, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.337383, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.683186, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.660081, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.401881, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.635264, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.635617, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.622938, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.854111, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.556636, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.634732, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.076198, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.007559, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.531114, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.041336, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 2.022564, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.647379, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.369538, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.379903, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.986917, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.318972, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.283966, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 0.936269, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.196061, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.739352, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.634901, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.201189, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.582981, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.742143, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.293135, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.748190, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.976545, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.357876, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.992895, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.602046, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.602167, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.173057, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.312798, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.564551, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 0.961713, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.274091, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.304703, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.958926, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.377168, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.657193, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.389767, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.576803, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.556738, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.175409, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.322616, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.251510, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.060407, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.661861, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.227308, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.597969, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.887250, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.338688, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.842966, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.160604, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.347215, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.223119, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.436648, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.535320, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.249121, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.248964, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.549803, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.259687, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.097239, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.324286, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.315431, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.420746, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.443017, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.301618, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.533658, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.607993, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.239065, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.649177, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.174445, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.602848, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.363682, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.160640, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.197888, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.126413, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.008120, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.643235, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.592807, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.412599, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.212850, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.196541, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.280346, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.403204, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.229377, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.400568, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.391042, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.102808, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.445285, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.406323, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.219193, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.449330, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.304464, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.494726, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.327706, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.361608, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.460816, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.424061, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.331042, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.319385, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.283704, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.309925, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.285989, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.352220, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.261306, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.287292, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.315104, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.268513, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.242892, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.047102, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.901234, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.948076, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.740618, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.914006, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.841368, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.927281, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.294955, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.815748, Train accuracy: 0.400000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.302894, Train accuracy: 0.150222, val accuracy: 0.138000\n",
      "Loss: 2.302708, Train accuracy: 0.168111, val accuracy: 0.158000\n",
      "Loss: 2.302067, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302612, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301671, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301938, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300620, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300583, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299049, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301054, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300701, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296117, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300853, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298154, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300848, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298265, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299789, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302017, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298812, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298901, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300413, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299959, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295737, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299950, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295571, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299891, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298026, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296357, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296505, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301949, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291493, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297171, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298733, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290846, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287811, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291046, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294175, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300730, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300097, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294588, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303368, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288573, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288903, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300376, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290867, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290001, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294812, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291852, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291844, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291468, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278472, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296630, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294019, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288173, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287820, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284846, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290937, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292018, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300542, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292936, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285185, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288995, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292374, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277094, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289712, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298877, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289586, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289138, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274714, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293641, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.304884, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285700, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301107, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290487, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291411, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292956, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294181, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281969, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.268213, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287892, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294997, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281607, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290212, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282788, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285199, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282436, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.272564, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280010, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279734, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284115, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284051, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282789, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288165, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277780, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291479, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290090, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290820, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280776, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283177, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278060, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291651, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286685, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289593, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289865, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291789, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269193, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.268614, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276377, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290226, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303665, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.273624, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.263329, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.272567, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293202, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296150, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279081, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276876, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289969, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277657, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269310, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265713, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.272650, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290365, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281629, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285411, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290140, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258187, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.282489, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285079, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276091, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259529, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302857, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276423, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292543, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279317, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262619, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289587, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277556, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275449, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258877, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260053, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290663, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.251553, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282493, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281260, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283622, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284957, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278744, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.248441, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299252, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301463, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280335, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.268282, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259269, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.249531, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.261426, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.307169, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290078, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.239154, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291229, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.247239, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281587, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260958, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.263625, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243457, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259489, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289466, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253902, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278195, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281019, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274770, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297417, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296363, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.245287, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281237, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.248091, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270124, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282357, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.251614, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257536, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257556, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277846, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283941, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282890, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282690, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269435, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.251054, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270304, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291664, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.233128, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243199, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269696, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.244860, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.254446, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250266, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258835, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.247454, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277307, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296073, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265353, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = 1e-4\n",
    "reg_strength = 1e-3\n",
    "learning_rate_decay = 0.999\n",
    "hidden_layer_size = 128\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = hidden_layer_size, \n",
    "                    reg = reg_strength)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=learning_rates, num_epochs=num_epochs, \n",
    "                  batch_size=batch_size, learning_rate_decay=learning_rate_decay)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "#print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19e28cc9400>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.182000\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
